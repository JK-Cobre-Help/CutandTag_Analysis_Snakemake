configfile: "config/config.yml"

##################################################################
##                    Define input functions                    ##
##################################################################

# Author: Kevin Boyd
# Date: Oct 18, 2024

import pandas as pd

# read the CSV file and set an index using the values in the "sample" column.
samples_table = pd.read_csv("config/samples.csv").set_index("sample", drop=False)

# fastq filename input function definition set to Python dictionary
def fq_dict_from_sample(wildcards):
  return {
    "fq1": samples_table.loc[wildcards.sample, "fastq1"],
    "fq2": samples_table.loc[wildcards.sample, "fastq2"]
  }

# make a new sample table with only the 'treatment' sample rows
samples_table2 = samples_table.loc[samples_table['sampleType'] == 'treatment']

# sample_type input function definition set to Python dictionary
def sample_type_dict_from_sample(wildcards):
  return {
    "treatment": 'results/aligned/' + samples_table2.loc[wildcards.sample, "sample"] + '.bam',
    "control": 'results/aligned/' + samples_table2.loc[wildcards.sample, "Control"] + '.bam'
  }

##################################################################
##                          Rule All                            ##
##################################################################

rule all:
    input:
        expand("results/qc/fastqc/{sample}_R1_fastqc.html", sample=samples_table.index),
        expand("results/qc/fastq_screen/{sample}_screen.txt", sample=samples_table.index),
        expand("results/alignment/sam/{sample}_bowtie2.sam", sample=samples_table.index),
        expand("results/alignment/bam/{sample}_bowtie2.bam", sample=samples_table.index),
        expand("results/alignment/bam/{sample}.sorted.bam", sample=samples_table.index),
        expand("results/alignment/bigwig/{sample}_raw.bw", sample=samples_table.index),
        expand("results/alignment/{sample}_total_reads.txt", sample=samples_table.index),
        expand("results/alignment/{sample}_scale_factor.txt", sample=samples_table.index),
        expand("results/alignment/bigwig/scale_reads/{sample}_scaled.bw", sample=samples_table.index),
        expand("results/peakCalling/{sample}_peaks.narrowPeak", sample=samples_table.index)

##################################################################
##                       Quality Control                        ##
##################################################################

# run fastqc on fastq.gz files before trimming
rule fastqc_reads:
    input:
        unpack(fq_dict_from_sample)   # <--- we need to wrap our input function inside a special Snakemake function called unpack() which turns the dict into a collection of named inputs
    output:
        html1="results/qc/fastqc/{sample}_R1_fastqc.html",
        zip1="results/qc/fastqc/{sample}_R1_fastqc.zip",
        html2="results/qc/fastqc/{sample}_R2_fastqc.html",
        zip2="results/qc/fastqc/{sample}_R2_fastqc.zip"
    envmodules:
        config["fastqc"]
    log: "results/logs/snakelogs/fastqc_reads.{sample}.log"
    shell:
        """
        fastqc {input.fq1}
        fastqc {input.fq2}
        dir=$(dirname {input.fq1})
        bsename=$(basename {input.fq1} .gz)
        bsename=$(basename ${{bsename}} .fastq)
        mv ${{dir}}/${{bsename}}_fastqc.html {output.html1}
        mv ${{dir}}/${{bsename}}_fastqc.zip {output.zip1}
        bsename=$(basename {input.fq2} .gz)
        bsename=$(basename ${{bsename}} .fastq)
        mv ${{dir}}/${{bsename}}_fastqc.html {output.html2}
        mv ${{dir}}/${{bsename}}_fastqc.zip {output.zip2}
        """

rule fastq_screen:
    input:
        unpack(fq_dict_from_sample)
    output:
        fastq_screen_out="results/qc/fastq_screen/{sample}_screen.txt"
    envmodules:
        config["fastq_screen"]
    log: projPath + "/logs/fastq_screen_{sample}.log"
    shell:
        """
        fastq_screen --conf /hpc-prj/kirkland/shared/scripts/fastq_screen.conf --threads 16 --outdir {output.fastq_screen_out} {input.fq1}
        """

##################################################################
##                       Read Alignment                         ##
##################################################################

rule align_with_bowtie2:
    input:
        unpack(fq_dict_from_sample)
    output:
        sam_file="results/alignment/sam/{sample}_bowtie2.sam",
        bowtie2_summary="results/alignment/sam/bowtie2_summary/{sample}_bowtie2.txt"
    envmodules:
        config["bowtie2"]
    log: "results/logs/align_with_bowtie2_{sample}.log"
    shell:
        """
        bowtie2 --end-to-end --very-sensitive --no-mixed --no-discordant --phred33 -I 10 -X 700 -p 8 \
        -x /hpc-prj/kirkland/shared/scripts/mm10_bowtie2_index/mm10 \
        -1 {input.fq1} -2 {input.fq2} -S {output.sam_file} &> {output.bowtie2_summary}
        """

##################################################################
##                     SAM to BAM Conversion                    ##
##################################################################

rule sam_to_bam:
    input:
        sam_file="results/alignment/sam/{sample}_bowtie2.sam"
    output:
        bam_file="results/alignment/bam/{sample}_bowtie2.bam"
    envmodules:
        config["samtools"]
    log: "results/logs/sam_to_bam_{sample}.log"
    shell:
        """
        samtools view -bS {input.sam_file} > {output.bam_file}
        """

##################################################################
##                  BAM Sorting and Indexing                    ##
##################################################################

rule sort_bam:
    input:
        bam_file="results/alignment/bam/{sample}_bowtie2.bam"
    output:
        sorted_bam="results/alignment/bam/{sample}.sorted.bam"
    envmodules:
        config["samtools"]
    log: "results/logs/sort_bam_{sample}.log"
    shell:
        """
        samtools sort -o {output.sorted_bam} {input.bam_file}
        """

rule index_bam:
    input:
        sorted_bam="results/alignment/bam/{sample}.sorted.bam"
    output:
        bai="results/alignment/bam/{sample}.sorted.bam.bai"
    envmodules:
        config["samtools"]
    log: "results/logs/index_bam_{sample}.log"
    shell:
        """
        samtools index {input.sorted_bam}
        """

##################################################################
##                       BigWig Generation                      ##
##################################################################

rule make_bigwig_raw:
    input:
        sorted_bam="results/alignment/bam/{sample}.sorted.bam"
    output:
        bigwig="results/alignment/bigwig/{sample}_raw.bw"
    envmodules:
        config["deeptools"]
    log: "results/logs/make_bigwig_raw_{sample}.log"
    shell:
        """
        bamCoverage -b {input.sorted_bam} -o {output.bigwig}
        """

##################################################################
##                  Total Reads and Scale Factor                ##
##################################################################

rule calculate_total_reads:
    input:
        sorted_bam="results/alignment/bam/{sample}.sorted.bam"
    output:
        total_reads="results/alignment/{sample}_total_reads.txt",
        scale_factor="results/alignment/{sample}_scale_factor.txt"
    envmodules:
        config["samtools"]
    log: "results/logs/calculate_total_reads_{sample}.log"
    shell:
        """
        total_reads=$(samtools view -c -F 4 {input.sorted_bam})
        scale_factor=$(echo "1 / ($total_reads / 1000000)" | bc -l)
        echo $total_reads > {output.total_reads}
        echo $scale_factor > {output.scale_factor}
        """

##################################################################
##              Scaled BigWig with Normalization                ##
##################################################################

rule make_bigwig_scaled:
    input:
        sorted_bam="results/alignment/bam/{sample}.sorted.bam",
        scale_factor="results/alignment/{sample}_scale_factor.txt"
    output:
        bigwig_scaled="results/alignment/bigwig/scale_reads/{sample}_scaled.bw"
    envmodules:
        config["deeptools"]
    log: "results/logs/make_bigwig_scaled_{sample}.log"
    shell:
        """
        scale_factor=$(cat {input.scale_factor})
        bamCoverage -b {input.sorted_bam} -o {output.bigwig_scaled} --scaleFactor $scale_factor
        """

##################################################################
##                        MACS2 Peak Calling                    ##
##################################################################

rule macs2_peak_calling:
    input:
        bam="results/alignment/bam/{sample}.sorted.bam"
    output:
        peaks="results/peakCalling/{sample}_peaks.narrowPeak"
    params:
        genome=config["genome_size"],
        qvalue=config["macs2_qvalue"],
        sample_name="{sample}",
        output_dir="results/peakCalling/"
    envmodules:
        config["macs2"]
    log: "results/logs/snakelogs/macs2_peak_calling.{sample}.log"
    shell:
        """
        macs2 callpeak -t {input.bam} \
        -g {params.genome} -f BAMPE -n {params.sample_name}_{params.qvalue} \
        --outdir {output.output_dir} -q {params.qvalue} --keep-dup all --nomodel \
        2>{params.output_dir}/{params.sample_name}_macs2Peak_summary.txt
        """
